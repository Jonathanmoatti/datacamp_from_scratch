{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teen titans\n",
      "justice league\n"
     ]
    }
   ],
   "source": [
    "# %load Chapter 2 - Default arguments, variable-length arguments and scope.py\n",
    "\n",
    "#Chapter 2 Default arguments, variable-length arguments and scope\n",
    "\n",
    "#The keyword global\n",
    "\n",
    "# Create a string: team\n",
    "team = \"teen titans\"\n",
    "\n",
    "# Define change_team()\n",
    "def change_team():\n",
    "    \"\"\"Change the value of the global variable team.\"\"\"\n",
    "\n",
    "    # Use team in global scope\n",
    "    global team\n",
    "\n",
    "    # Change the value of team in global: team\n",
    "    team=\"justice league\"\n",
    "\n",
    "# Print team\n",
    "print(team)\n",
    "\n",
    "# Call change_team()\n",
    "change_team()\n",
    "\n",
    "# Print team\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a!!!', 'b!!!', 'c!!!')\n"
     ]
    }
   ],
   "source": [
    "#Nested Functions I\n",
    "\n",
    "# Define three_shouts\n",
    "def three_shouts(word1, word2, word3):\n",
    "    \"\"\"Returns a tuple of strings\n",
    "    concatenated with '!!!'.\"\"\"\n",
    "\n",
    "    # Define inner\n",
    "    def inner(word):\n",
    "        \"\"\"Returns a string concatenated with '!!!'.\"\"\"\n",
    "        return word + '!!!'\n",
    "\n",
    "    # Return a tuple of strings\n",
    "    return (inner(word1), inner(word2), inner(word3))\n",
    "\n",
    "# Call three_shouts() and print\n",
    "print(three_shouts('a', 'b', 'c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello hellohellohello\n"
     ]
    }
   ],
   "source": [
    "#Nested Functions II\n",
    "\n",
    "# Define echo\n",
    "def echo(n):\n",
    "    \"\"\"Return the inner_echo function.\"\"\"\n",
    "\n",
    "    # Define inner_echo\n",
    "    def inner_echo(word1):\n",
    "        \"\"\"Concatenate n copies of word1.\"\"\"\n",
    "        echo_word = word1 * n\n",
    "        return echo_word\n",
    "\n",
    "    # Return inner_echo\n",
    "    return inner_echo\n",
    "\n",
    "# Call echo: twice\n",
    "twice = echo(2)\n",
    "\n",
    "# Call echo: thrice\n",
    "thrice = echo(3)\n",
    "\n",
    "# Call twice() and thrice() then print\n",
    "print(twice('hello'), thrice('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello\n",
      "hellohello!!!\n"
     ]
    }
   ],
   "source": [
    "#The keyword nonlocal and nested functions\n",
    "\n",
    "# Define echo_shout()\n",
    "def echo_shout(word):\n",
    "    \"\"\"Change the value of a nonlocal variable\"\"\"\n",
    "    \n",
    "    # Concatenate word with itself: echo_word\n",
    "    echo_word = word*2\n",
    "    \n",
    "    #Print echo_word\n",
    "    print(echo_word)\n",
    "    \n",
    "    # Define inner function shout()\n",
    "    def shout():\n",
    "        \"\"\"Alter a variable in the enclosing scope\"\"\"\n",
    "        \n",
    "        #Use echo_word in nonlocal scope\n",
    "        nonlocal echo_word\n",
    "        \n",
    "        #Change echo_word to echo_word concatenated with '!!!'\n",
    "        echo_word = echo_word + '!!!'\n",
    "    \n",
    "    # Call function shout()\n",
    "    shout()\n",
    "\n",
    "    #Print echo_word\n",
    "    print(echo_word)\n",
    "\n",
    "#Call function echo_shout() with argument 'hello'    \n",
    "echo_shout('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey!!!\n",
      "HeyHeyHeyHeyHey!!!\n"
     ]
    }
   ],
   "source": [
    "#Functions with one default argument\n",
    "\n",
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "     exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1*echo\n",
    "\n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "\n",
    "    # Return shout_word\n",
    "    return shout_word\n",
    "\n",
    "# Call shout_echo() with \"Hey\": no_echo\n",
    "no_echo =shout_echo(\"Hey\")\n",
    "\n",
    "# Call shout_echo() with \"Hey\" and echo=5: with_echo\n",
    "with_echo = shout_echo(\"Hey\",echo=5)\n",
    "\n",
    "# Print no_echo and with_echo\n",
    "print(no_echo)\n",
    "print(with_echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEYHEYHEYHEYHEY!!!\n",
      "HEY!!!\n"
     ]
    }
   ],
   "source": [
    "#Functions with multiple default arguments\n",
    "\n",
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1, intense=False):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "\n",
    "    # Capitalize echo_word if intense is True\n",
    "    if intense is True:\n",
    "        # Capitalize and concatenate '!!!': echo_word_new\n",
    "        echo_word_new = echo_word.upper() + '!!!'\n",
    "    else:\n",
    "        # Concatenate '!!!' to echo_word: echo_word_new\n",
    "        echo_word_new = echo_word + '!!!'\n",
    "\n",
    "    # Return echo_word_new\n",
    "    return echo_word_new\n",
    "\n",
    "# Call shout_echo() with \"Hey\", echo=5 and intense=True: with_big_echo\n",
    "with_big_echo = shout_echo(\"Hey\",echo=5 ,intense=True)\n",
    "\n",
    "# Call shout_echo() with \"Hey\" and intense=True: big_no_echo\n",
    "big_no_echo = shout_echo(\"Hey\", intense=True)\n",
    "\n",
    "# Print values\n",
    "print(with_big_echo)\n",
    "print(big_no_echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luke\n",
      "lukeleiahanobidarth\n"
     ]
    }
   ],
   "source": [
    "#Function with variable-length arguments (*args)\n",
    "\n",
    "# Define gibberish\n",
    "def gibberish(*args):\n",
    "    \"\"\"Concatenate strings in *args together.\"\"\"\n",
    "\n",
    "    # Initialize an empty string: hodgepodge\n",
    "    hodgepodge=\"\"\n",
    "\n",
    "    # Concatenate the strings in args\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "\n",
    "    # Return hodgepodge\n",
    "    return hodgepodge\n",
    "\n",
    "# Call gibberish() with one string: one_word\n",
    "one_word = gibberish(\"luke\")\n",
    "\n",
    "# Call gibberish() with five strings: many_words\n",
    "many_words = gibberish(\"luke\", \"leia\", \"han\", \"obi\", \"darth\")\n",
    "\n",
    "# Print one_word and many_words\n",
    "print(one_word)\n",
    "print(many_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: luke\n",
      "affiliation: jedi\n",
      "status: missing\n",
      "\n",
      "END REPORT\n",
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: anakin\n",
      "affiliation: sith lord\n",
      "status: deceased\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "#Function with variable-length keyword arguments (**kwargs)\n",
    "\n",
    "# Define report_status\n",
    "def report_status(**kwargs):\n",
    "    \"\"\"Print out the status of a movie character.\"\"\"\n",
    "\n",
    "    print(\"\\nBEGIN: REPORT\\n\")\n",
    "\n",
    "    # Print a formatted status report\n",
    "    for key, value in kwargs.items():\n",
    "        print(key + \": \" + value)\n",
    "\n",
    "    print(\"\\nEND REPORT\")\n",
    "\n",
    "# First call to report_status()\n",
    "report_status(name=\"luke\", affiliation=\"jedi\", status=\"missing\")\n",
    "\n",
    "# Second call to report_status()\n",
    "report_status(name=\"anakin\", affiliation=\"sith lord\", status=\"deceased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mmonn\\\\Desktop\\\\DataCamp\\\\Data Scientist with Python\\\\Data Scientist with Python\\\\Courses\\\\Python Data Science Toolbox (Part 1)\\\\Jupyter Notebook'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"c:\\\\Users\\\\mmonn\\\\Desktop\\\\DataCamp\\\\Data Scientist with Python\\\\Data Scientist with Python\\\\Courses\\\\Python Data Science Toolbox (Part 1)\")"
   ]
  },
  {
   "source": [
    "pwd"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mmonn\\\\Desktop\\\\DataCamp\\\\Data Scientist with Python\\\\Data Scientist with Python\\\\Courses\\\\Python Data Science Toolbox (Part 1)'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing it all together (1)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy\n",
    "tweets_df = pd.read_csv('Datasets\\\\tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['contributors', 'coordinates', 'created_at', 'entities',\n",
       "       'extended_entities', 'favorite_count', 'favorited', 'filter_level',\n",
       "       'geo', 'id', 'id_str', 'in_reply_to_screen_name',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status',\n",
       "       'lang', 'place', 'possibly_sensitive', 'quoted_status',\n",
       "       'quoted_status_id', 'quoted_status_id_str', 'retweet_count',\n",
       "       'retweeted', 'retweeted_status', 'source', 'text', 'timestamp_ms',\n",
       "       'truncated', 'user'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "3           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "4           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "3  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "4  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "3      False          low  NaN  714960402367561730  ...      7.149239e+17   \n",
       "4      False          low  NaN  714960402149416960  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "3         7.149239e+17              0      False   \n",
       "4                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'retweeted': False, 'text': 'The anti-America...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...  1459294817917     False   \n",
       "3  Your an idiot she shouldn't have tried to grab...  1459294817903     False   \n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...  1459294817851     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "3  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "4  {'utc_offset': -18000, 'profile_image_url_http...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contributors</th>\n      <th>coordinates</th>\n      <th>created_at</th>\n      <th>entities</th>\n      <th>extended_entities</th>\n      <th>favorite_count</th>\n      <th>favorited</th>\n      <th>filter_level</th>\n      <th>geo</th>\n      <th>id</th>\n      <th>...</th>\n      <th>quoted_status_id</th>\n      <th>quoted_status_id_str</th>\n      <th>retweet_count</th>\n      <th>retweeted</th>\n      <th>retweeted_status</th>\n      <th>source</th>\n      <th>text</th>\n      <th>timestamp_ms</th>\n      <th>truncated</th>\n      <th>user</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>low</td>\n      <td>NaN</td>\n      <td>714960401759387648</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n      <td>1459294817758</td>\n      <td>False</td>\n      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>low</td>\n      <td>NaN</td>\n      <td>714960401977319424</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n      <td>1459294817810</td>\n      <td>False</td>\n      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>low</td>\n      <td>NaN</td>\n      <td>714960402426236928</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n      <td>1459294817917</td>\n      <td>False</td>\n      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>low</td>\n      <td>NaN</td>\n      <td>714960402367561730</td>\n      <td>...</td>\n      <td>7.149239e+17</td>\n      <td>7.149239e+17</td>\n      <td>0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n      <td>Your an idiot she shouldn't have tried to grab...</td>\n      <td>1459294817903</td>\n      <td>False</td>\n      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>low</td>\n      <td>NaN</td>\n      <td>714960402149416960</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>{'retweeted': False, 'text': 'The anti-America...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n      <td>1459294817851</td>\n      <td>False</td>\n      <td>{'utc_offset': -18000, 'profile_image_url_http...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dict = {'pew':'foo', 'mew': 'bar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File \\Datasets\tweets.csv does not exist: '\\\\Datasets\\tweets.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a88720295ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtweets_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\Datasets\\tweets.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Define count_entries()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File \\Datasets\tweets.csv does not exist: '\\\\Datasets\\tweets.csv'"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df,col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "\n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If entry is in cols_count, add 1\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "\n",
    "        # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df,'lang')\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df,'source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "{'en': 97, 'et': 1, 'und': 2, '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "#Bringing it all together (2)\n",
    "\n",
    "# Define count_entries()\n",
    "def count_entries(df, *args):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    #Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Iterate over column names in args\n",
    "    for col_name in args:\n",
    "    \n",
    "        # Extract column from DataFrame: col\n",
    "        col = df[col_name]\n",
    "    \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in col:\n",
    "    \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "    \n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'lang', 'source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}